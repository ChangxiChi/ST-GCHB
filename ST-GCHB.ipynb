{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VIVIBLE_DEVICES\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zjj/anaconda3/envs/ccx_rp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.3\n",
      "4\n",
      "10\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import config as CFG\n",
    "from models import ST_GCHB\n",
    "from dataset import ST_GCHB_Dataset\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import neighbors\n",
    "import torch.utils.data.distributed\n",
    "import scipy.sparse\n",
    "\n",
    "#print the current scanpy version\n",
    "print(sc.__version__)\n",
    "epoch=CFG.epochs\n",
    "print(epoch)\n",
    "print(CFG.topk)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_umap_clusters(expr_matrix, preprocess = True, normalize_and_log = True, batch_idx = None, n_neighbors=150, n_top_genes=1024, max_value=10, legend_loc='on data', show=False, save=False, save_name='umap_clusters.png'):\n",
    "    #! scanpy input matrix has cells as rows and genes as columns, same as this function\n",
    "    if preprocess:\n",
    "        # # Filter out genes with expression in less than 50 spots (for a ~8000 spot dataset over 4 slices)\n",
    "        # expressed = np.sum(expr_matrix>0, axis=0)\n",
    "        # expr_matrix = expr_matrix[:,expressed>50]\n",
    "\n",
    "        # Create AnnData object with batch index as an observation\n",
    "        adata = sc.AnnData(X=expr_matrix, dtype=expr_matrix.dtype)\n",
    "        if batch_idx is not None: \n",
    "            adata.obs['batch_idx'] = batch_idx\n",
    "\n",
    "        # Preprocess the data\n",
    "        if normalize_and_log:\n",
    "            sc.pp.normalize_total(adata)\n",
    "            sc.pp.log1p(adata)\n",
    "        sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)\n",
    "        print(\"n_top_genes: \", adata.var['highly_variable'].sum())\n",
    "        # sc.pp.scale(adata, max_value=max_value)\n",
    "    else: # false\n",
    "        adata = sc.AnnData(X=expr_matrix, dtype=expr_matrix.dtype)\n",
    "        if batch_idx is not None:\n",
    "            adata.obs['batch_idx'] = batch_idx\n",
    "\n",
    "    # Run UMAP and clustering on the preprocessed data\n",
    "    # sc.pp.scale(adata, max_value=max_value)\n",
    "    sc.pp.pca(adata, n_comps=50, use_highly_variable=preprocess)\n",
    "    sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=50)\n",
    "    \n",
    "    sc.tl.umap(adata)\n",
    "    print(\"Running Leiden clustering\")\n",
    "    sc.tl.leiden(adata)\n",
    "    print(\"n_clusters: \", adata.obs['leiden'].nunique())\n",
    "    print(\"Plotting UMAP clusters\")\n",
    "\n",
    "    # Plot the UMAP embedding with cell clusters and batch index\n",
    "    if batch_idx is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        sc.pl.umap(adata, color='leiden', ax=ax, show=show, legend_loc=legend_loc)\n",
    "\n",
    "        # Save the figure\n",
    "        if save:\n",
    "            fig.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "        return adata\n",
    "\n",
    "    else:\n",
    "        fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "\n",
    "        # Plot the UMAP embedding with cell clusters\n",
    "        sc.pl.umap(adata, color='leiden', ax=axs[0], show=False, legend_loc=legend_loc)\n",
    "\n",
    "        # Plot the UMAP embedding with batch information\n",
    "        sc.pl.umap(adata, color='batch_idx', ax=axs[1], show=False, legend_loc=legend_loc)\n",
    "\n",
    "\n",
    "        # Save the figure\n",
    "        if save:\n",
    "            fig.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "        return adata\n",
    "\n",
    "def Cal_Spatial_Net(dataset, rad=CFG.radius, k=CFG.topk):  \n",
    "    X = torch.Tensor()  # tensor([])\n",
    "    for idx in range(len(dataset)):\n",
    "        if idx == 0:\n",
    "            X = np.append(X, dataset[idx]['spatial_coords'])  # tensor([a,b])\n",
    "            X = torch.from_numpy(X)  # from array to tensor\n",
    "            X = X.unsqueeze(0)  # shape:[[a,b]]\n",
    "        else:\n",
    "            coor = [dataset[idx]['spatial_coords']]\n",
    "            X = np.append(X, coor, axis=0)\n",
    "    nbrs = neighbors.NearestNeighbors(n_neighbors=k + 1).fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    KNN_list = []\n",
    "    for it in range(indices.shape[0]):\n",
    "        KNN_list.append(pd.DataFrame(zip([it] * indices.shape[1], indices[it, :], distances[it, :])))\n",
    "    # print(KNN_list)\n",
    "    adj = np.zeros((indices.shape[0], indices.shape[0]))\n",
    "    KNN_list = np.array(KNN_list)\n",
    "    for idx in range(len(KNN_list)):\n",
    "        t = KNN_list[idx, :]  \n",
    "        for p in range(len(t)):  \n",
    "            if t[p,2]<rad:\n",
    "                x = int(t[p, 0])\n",
    "                y = int(t[p, 1])\n",
    "                adj[x, y] = 1\n",
    "    return adj\n",
    "\n",
    "def build_loaders_inference():\n",
    "    print(\"Building loaders\")\n",
    "    print(\"topk:\",CFG.topk)\n",
    "\n",
    "    # load all of your slices as follow:\n",
    "    dataset1 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_1.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/1/harmony1.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/1/barcodes1.tsv\")\n",
    "    dataset2 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_2.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/2/harmony2.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/2/barcodes2.tsv\")\n",
    "    dataset3 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_3.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/3/harmony3.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/3/barcodes3.tsv\")\n",
    "    dataset4 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_4.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/4/harmony4.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/4/barcodes4.tsv\")\n",
    "    dataset5 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_5.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/5/harmony5.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/5/barcodes5.tsv\")\n",
    "    dataset6 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_6.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/6/harmony6.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/6/barcodes6.tsv\")\n",
    "    dataset7 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_7.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/7/harmony7.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/7/barcodes7.tsv\")\n",
    "    dataset8 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_8.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/8/harmony8.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/8/barcodes8.tsv\")\n",
    "    dataset9 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_9.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/9/harmony9.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/9/barcodes9.tsv\")\n",
    "    dataset10 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_10.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/10/harmony10.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/10/barcodes10.tsv\")\n",
    "    dataset11 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_11.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/11/harmony11.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/11/barcodes11.tsv\")\n",
    "    dataset12 = ST_GCHB_Dataset(\n",
    "                spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_12.csv\",\n",
    "                reduced_mtx_path = \"./data/filtered_expression_matrices/12/harmony12.npy\",\n",
    "                barcode_path = \"./data/filtered_expression_matrices/12/barcodes12.tsv\")\n",
    "\n",
    "    \n",
    "    adj1 = Cal_Spatial_Net(dataset1, CFG.radius, CFG.topk)\n",
    "    adj2 = Cal_Spatial_Net(dataset2, CFG.radius, CFG.topk)\n",
    "    adj3 = Cal_Spatial_Net(dataset3, CFG.radius, CFG.topk)\n",
    "    adj4 = Cal_Spatial_Net(dataset4, CFG.radius, CFG.topk)\n",
    "    adj5 = Cal_Spatial_Net(dataset5, CFG.radius, CFG.topk)\n",
    "    adj6 = Cal_Spatial_Net(dataset6, CFG.radius, CFG.topk)\n",
    "    adj7 = Cal_Spatial_Net(dataset7, CFG.radius, CFG.topk)\n",
    "    adj8 = Cal_Spatial_Net(dataset8, CFG.radius, CFG.topk)\n",
    "    adj9 = Cal_Spatial_Net(dataset9, CFG.radius, CFG.topk)\n",
    "    adj10 = Cal_Spatial_Net(dataset10, CFG.radius, CFG.topk)\n",
    "    adj11 = Cal_Spatial_Net(dataset11, CFG.radius, CFG.topk)\n",
    "    adj12 = Cal_Spatial_Net(dataset12, CFG.radius, CFG.topk)\n",
    "    adj1 = scipy.sparse.coo_matrix(adj1)\n",
    "    adj2 = scipy.sparse.coo_matrix(adj2)\n",
    "    adj3 = scipy.sparse.coo_matrix(adj3)\n",
    "    adj4 = scipy.sparse.coo_matrix(adj4)\n",
    "    adj5 = scipy.sparse.coo_matrix(adj5)\n",
    "    adj6 = scipy.sparse.coo_matrix(adj6)\n",
    "    adj7 = scipy.sparse.coo_matrix(adj7)\n",
    "    adj8 = scipy.sparse.coo_matrix(adj8)\n",
    "    adj9 = scipy.sparse.coo_matrix(adj9)\n",
    "    adj10 = scipy.sparse.coo_matrix(adj10)\n",
    "    adj11 = scipy.sparse.coo_matrix(adj11)\n",
    "    adj12 = scipy.sparse.coo_matrix(adj12)\n",
    "    \n",
    "    print(\"Finished building loaders\")\n",
    "    return (dataset1,dataset2,dataset3,dataset4,dataset5,dataset6,dataset7,dataset8,dataset9,dataset10,dataset11,dataset12,\n",
    "            adj1,adj2,adj3,adj4,adj5,adj6,adj7,adj8,adj9,adj10,adj11,adj12)\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "def get_image_embeddings(model): # your testing slice\n",
    "    dataset = ST_GCHB_Dataset(\n",
    "            spatial_pos_path = \"./data/tissue_pos_matrices/tissue_positions_list_X.csv\",\n",
    "            reduced_mtx_path = \"./data/filtered_expression_matrices/X/harmonyX.npy\",\n",
    "            barcode_path = \"./data/filtered_expression_matrices/X/barcodesX.tsv\")\n",
    "    adj = Cal_Spatial_Net(dataset, CFG.radius, CFG.topk)\n",
    "    adj = scipy.sparse.coo_matrix(adj)\n",
    "    sp_Adj = sparse_mx_to_torch_sparse_tensor(adj).cuda()\n",
    "    graph_batch=torch.load(\"data/graph_batch_X.pt\").cuda()\n",
    "    with torch.no_grad():\n",
    "        features=model.image_encoder(graph_batch)\n",
    "        features=model.image_dgi_model.model.embed(features,sp_Adj,1,None)\n",
    "        image_embeddings=model.image_projection(features)\n",
    "    return image_embeddings\n",
    "        \n",
    "\n",
    "dataset=torch.load('pca_res.pt')\n",
    "\n",
    "def get_spot_embeddings( model):\n",
    "    #only traing slices\n",
    "    _,_,_,_,_,_,_,_,_,_,_,_,adj1,adj2,adj3,adj4,adj5,adj6,adj7,adj8,adj9,adj10,_,_ = build_loaders_inference()\n",
    "    \n",
    "    sp_Adj1 = sparse_mx_to_torch_sparse_tensor(adj1)\n",
    "    sp_Adj2 = sparse_mx_to_torch_sparse_tensor(adj2)\n",
    "    sp_Adj3 = sparse_mx_to_torch_sparse_tensor(adj3)\n",
    "    sp_Adj4 = sparse_mx_to_torch_sparse_tensor(adj4)\n",
    "    sp_Adj5 = sparse_mx_to_torch_sparse_tensor(adj5)\n",
    "    sp_Adj6 = sparse_mx_to_torch_sparse_tensor(adj6)\n",
    "    sp_Adj7 = sparse_mx_to_torch_sparse_tensor(adj7)\n",
    "    sp_Adj8 = sparse_mx_to_torch_sparse_tensor(adj8)\n",
    "    sp_Adj9 = sparse_mx_to_torch_sparse_tensor(adj9)\n",
    "    sp_Adj10 = sparse_mx_to_torch_sparse_tensor(adj10)\n",
    "    List=list([adj1.shape[0],adj2.shape[0],adj3.shape[0],adj4.shape[0],adj5.shape[0],adj6.shape[0],adj7.shape[0],\n",
    "               adj8.shape[0],adj9.shape[0],adj10.shape[0]])\n",
    "    t=0\n",
    "    for i in range(len(List)):\n",
    "        if i==0:\n",
    "            dataset1=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==1:\n",
    "            dataset2=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==2:\n",
    "            dataset3=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==3:\n",
    "            dataset4=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==4:\n",
    "            dataset5=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==5:\n",
    "            dataset6=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==6:\n",
    "            dataset7=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==7:\n",
    "            dataset8=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==8:\n",
    "            dataset9=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "        elif i==9:\n",
    "            dataset10=dataset[t:t+List[i],:]\n",
    "            t+=List[i]\n",
    "    with torch.no_grad():\n",
    "        for epoch in range(10):  \n",
    "            if epoch == 0:\n",
    "                adj = sp_Adj1\n",
    "                train_loader=dataset1\n",
    "            elif epoch == 1:\n",
    "                adj = sp_Adj2\n",
    "                train_loader=dataset2\n",
    "            elif epoch==2:\n",
    "                adj = sp_Adj3\n",
    "                train_loader=dataset3\n",
    "            elif epoch==3:\n",
    "                adj = sp_Adj4\n",
    "                train_loader=dataset4\n",
    "            elif epoch==4:\n",
    "                adj = sp_Adj5\n",
    "                train_loader=dataset5\n",
    "            elif epoch==5:\n",
    "                adj = sp_Adj6\n",
    "                train_loader=dataset6\n",
    "            elif epoch==6:\n",
    "                adj = sp_Adj7\n",
    "                train_loader=dataset7\n",
    "            elif epoch==7:\n",
    "                adj = sp_Adj8\n",
    "                train_loader=dataset8\n",
    "            elif epoch==8:\n",
    "                adj = sp_Adj9\n",
    "                train_loader=dataset9\n",
    "            elif epoch==9:\n",
    "                adj = sp_Adj10\n",
    "                train_loader=dataset10\n",
    "            torch.cuda.empty_cache()\n",
    "            gene_fts=train_loader.cuda()\n",
    "            gene_fts = gene_fts.unsqueeze(0)\n",
    "            adj=adj.cuda()\n",
    "            feature = model.spot_dgi_model.model.embed(gene_fts, adj, 1,None)\n",
    "            feature=model.spot_projection(feature)\n",
    "            print(\"spot_feature:\",feature.shape)\n",
    "            if epoch == 0:\n",
    "                features_1=feature\n",
    "            elif epoch == 1:\n",
    "                features_2=feature\n",
    "            elif epoch == 2:\n",
    "                features_3=feature\n",
    "            elif epoch == 3:\n",
    "                features_4=feature\n",
    "            elif epoch==4:\n",
    "                features_5=feature\n",
    "            elif epoch==5:\n",
    "                features_6=feature\n",
    "            elif epoch==6:\n",
    "                features_7=feature\n",
    "            elif epoch==7:\n",
    "                features_8=feature\n",
    "            elif epoch==8:\n",
    "                features_9=feature\n",
    "            elif epoch==9:\n",
    "                features_10=feature\n",
    "            torch.cuda.empty_cache()\n",
    "    return features_1, features_2,features_3,features_4,features_5,features_6,features_7,features_8,features_9,features_10\n",
    "   \n",
    "def find_matches(spot_embeddings, query_embeddings, top_k=50):\n",
    "    #find the closest matches\n",
    "    spot_embeddings = torch.tensor(spot_embeddings)\n",
    "    query_embeddings = torch.tensor(query_embeddings)\n",
    "    # query_embeddings = F.normalize(query_embeddings, p=2, dim=-1)\n",
    "    # spot_embeddings = F.normalize(spot_embeddings, p=2, dim=-1)\n",
    "    dot_similarity = query_embeddings @ spot_embeddings.T   \n",
    "    print(dot_similarity.shape)\n",
    "    _, indices = torch.topk(dot_similarity.squeeze(0), k=top_k)\n",
    "\n",
    "\n",
    "    return indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zjj/anaconda3/envs/ccx_rp/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zjj/anaconda3/envs/ccx_rp/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image encoder is ResNet50\n",
      "finshed loading ST-GCHB\n",
      "Finished loading all files\n",
      "Building loaders\n",
      "topk: 10\n",
      "Finished loading all files\n",
      "Finished loading all files\n",
      "Finished loading all files\n",
      "Finished loading all files\n",
      "Finished loading all files\n",
      "Finished loading all files\n",
      "Finished loading all files\n",
      "Finished loading all files\n",
      "Finished building loaders\n",
      "spot_feature: torch.Size([1, 3661, 128])\n",
      "spot_feature: torch.Size([1, 3498, 128])\n",
      "spot_feature: torch.Size([1, 4110, 128])\n",
      "spot_feature: torch.Size([1, 4015, 128])\n",
      "spot_feature: torch.Size([1, 3639, 128])\n",
      "spot_feature: torch.Size([1, 3673, 128])\n",
      "spot_feature: torch.Size([1, 3592, 128])\n",
      "torch.Size([1, 3460, 128])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())\n",
    "ST_GCHB_model_path = \"./ST_GCHB.pt\"\n",
    "\n",
    "save_path = \"./embeddings/\"\n",
    "model=ST_GCHB().cuda()\n",
    "model.load_state_dict(torch.load(ST_GCHB_model_path))\n",
    "model.eval()\n",
    "print(\"finshed loading ST-GCHB\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_embeddings_test=get_image_embeddings(model) \n",
    "    spt_emb_1,spt_emb_2,spt_emb_3,spt_emb_4,spt_emb_5,spt_emb_6,spt_emb_7,spt_emb_8,spt_emb_9,spt_emb_10=get_spot_embeddings(model)\n",
    "\n",
    "print(image_embeddings_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_feature:  (3460, 128)\n",
      "spot_feature_dataset:  (26188, 128)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Spot_embeddings_all = np.array(torch.concatenate([spt_emb_1, spt_emb_2, spt_emb_3,spt_emb_4,spt_emb_5,spt_emb_6,spt_emb_7,spt_emb_8\n",
    "                                                  ,spt_emb_9,spt_emb_10], axis = 1).cpu())\n",
    "image_query = np.array(image_embeddings_test.squeeze().cpu())\n",
    "spot_embeddings_all = Spot_embeddings_all.squeeze(0)\n",
    "print(\"image_feature: \",image_query.shape)\n",
    "print(\"spot_feature_dataset: \",spot_embeddings_all.shape)\n",
    "print(CFG.topk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test training set slice \n",
    "spot_expression1 = np.load(\"data/filtered_expression_matrices/1/harmony1.npy\")\n",
    "spot_expression2 = np.load(\"data/filtered_expression_matrices/2/harmony2.npy\")\n",
    "spot_expression3 = np.load(\"data/filtered_expression_matrices/3/harmony3.npy\")\n",
    "spot_expression4 = np.load(\"data/filtered_expression_matrices/4/harmony4.npy\")\n",
    "spot_expression5 = np.load(\"data/filtered_expression_matrices/5/harmony5.npy\")\n",
    "spot_expression6 = np.load(\"data/filtered_expression_matrices/6/harmony6.npy\")\n",
    "spot_expression7 = np.load(\"data/filtered_expression_matrices/7/harmony7.npy\")\n",
    "spot_expression8 = np.load(\"data/filtered_expression_matrices/8/harmony8.npy\")\n",
    "spot_expression9 = np.load(\"data/filtered_expression_matrices/5/harmony9.npy\")\n",
    "spot_expression10 = np.load(\"data/filtered_expression_matrices/6/harmony10.npy\")\n",
    "spot_expression11 = np.load(\"data/filtered_expression_matrices/7/harmony11.npy\")\n",
    "spot_expression12 = np.load(\"data/filtered_expression_matrices/8/harmony12.npy\")\n",
    "spot_key = spot_embeddings_all\n",
    "expression_key = np.concatenate([spot_expression1, spot_expression2,spot_expression3,spot_expression4,spot_expression5,spot_expression6,\n",
    "                                 spot_expression7,spot_expression8,spot_expression9,spot_expression10], axis = 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expression_key shape:  (26188, 2000)\n",
      "finding matches, using average of top 50 expressions\n",
      "torch.Size([3460, 26188])\n",
      "matched spot embeddings pred shape:  (3460, 128)\n",
      "matched spot expression pred shape:  (3460, 2000)\n",
      "pred shape: (2000, 3460)\n",
      "true shape: (2000, 3460)\n",
      "Mean correlation acroalignment uniformityss cells:  0.7666696661492286\n",
      "number of non-zero genes:  1856\n",
      "mean correlation:  0.09117149090205576\n",
      "max correlation:  0.796260696722005\n",
      "number of genes with correlation > 0.3:  152\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#query\n",
    "expression_gt = spot_expression8\n",
    "\n",
    "method = \"average\"\n",
    "save_path = \"\"\n",
    "print(\"expression_key shape: \", expression_key.shape)\n",
    "\n",
    "\n",
    "\n",
    "if method == \"average\":\n",
    "    print(\"finding matches, using average of top 50 expressions\")\n",
    "    indices = find_matches(spot_key, image_query, top_k=50)\n",
    "    matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "    matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "    for i in range(indices.shape[0]):\n",
    "        matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0)\n",
    "        matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0)\n",
    "\n",
    "    print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "    print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "\n",
    "true = expression_gt\n",
    "pred = matched_spot_expression_pred.T\n",
    "\n",
    "print(\"pred shape:\",pred.shape)\n",
    "print(\"true shape:\",true.shape)\n",
    "\n",
    "\n",
    "#genewise correlation\n",
    "corr = np.zeros(pred.shape[1])\n",
    "for i in range(pred.shape[1]):\n",
    "    corr[i] = np.corrcoef(pred[:,i], true[:,i])[0,1] #corrcoef returns a matrix\n",
    "#remove nan\n",
    "corr = corr[~np.isnan(corr)]\n",
    "print(\"Mean correlation acroalignment uniformityss cells: \", np.mean(corr))\n",
    "\n",
    "true = expression_gt.T\n",
    "pred = matched_spot_expression_pred\n",
    "corr = np.zeros(pred.shape[1])\n",
    "for i in range(pred.shape[1]):\n",
    "    corr[i] = np.corrcoef(pred[:,i], true[:,i],)[0,1] #corrcoef returns a matrix\n",
    "#remove nan\n",
    "corr = corr[~np.isnan(corr)]\n",
    "print(\"number of non-zero genes: \", corr.shape[0])\n",
    "print(\"mean correlation: \", np.mean(corr))\n",
    "print(\"max correlation: \", np.max(corr))\n",
    "print(\"number of genes with correlation > 0.3: \", np.sum(corr > 0.3))\n",
    "\n",
    "if save_path != \"\":\n",
    "    np.save(save_path + \"matched_spot_embeddings_pred.npy\", matched_spot_embeddings_pred.T)\n",
    "    np.save(save_path + \"matched_spot_expression_pred.npy\", matched_spot_expression_pred.T)\n",
    "\n",
    "\n",
    "\n",
    "print(type(pred))\n",
    "np.save('ST-GCHB.npy',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expression_key shape:  (26188, 2000)\n",
      "finding matches, using average of top 50 expressions\n",
      "torch.Size([3460, 26188])\n",
      "indice (3460, 50)\n",
      "matched spot embeddings pred shape:  (3460, 128)\n",
      "matched spot expression pred shape:  (3460, 2000)\n",
      "torch.Size([3460, 50])\n",
      "pred shape: (2000, 3460)\n",
      "true shape: (2000, 3460)\n",
      "Mean correlation acroalignment uniformityss cells:  0.7666752710712937\n",
      "[ 410 1590  365  852 1660]\n",
      "[0.64089478 0.65919728 0.67024712 0.74021874 0.79636672]\n",
      "number of non-zero genes:  1856\n",
      "mean correlation:  0.0911731853331799\n",
      "max correlation:  0.7963667219676384\n",
      "number of genes with correlation > 0.3:  152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#query2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def find_matches_weighted(spot_embeddings, query_embeddings, top_k=50):\n",
    "    #find the closest matches\n",
    "    spot_embeddings = torch.tensor(spot_embeddings)\n",
    "    query_embeddings = torch.tensor(query_embeddings)\n",
    "    # query_embeddings = F.normalize(query_embeddings, p=2, dim=-1)\n",
    "    # spot_embeddings = F.normalize(spot_embeddings, p=2, dim=-1)\n",
    "    dot_similarity = query_embeddings @ spot_embeddings.T /20 \n",
    "    print(dot_similarity.shape)\n",
    "    weight, indices = torch.topk(dot_similarity.squeeze(0), k=top_k)\n",
    "    \n",
    "    weight=F.softmax(-weight,dim=1)\n",
    "    # print(\"Weight\",weight.sum(axis=1).shape)  \n",
    "    return weight,indices.cpu().numpy()\n",
    "\n",
    "\n",
    "method = \"weighted\"\n",
    "save_path = \"\"\n",
    "print(\"expression_key shape: \", expression_key.shape)\n",
    "\n",
    "\n",
    "\n",
    "if method == \"weighted\":\n",
    "    print(\"finding matches, using weighted of top 50 expressions\")\n",
    "    Weight,indices = find_matches_weighted(spot_key, image_query, top_k=50)\n",
    "    print(\"indice\",indices.shape)\n",
    "    matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "    matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "    for i in range(indices.shape[0]):\n",
    "        matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0)\n",
    "        # matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0)\n",
    "        for j in range(50):\n",
    "            matched_spot_expression_pred[i,:] += expression_key[indices[i,j],:]*Weight[i,j].numpy()\n",
    "\n",
    "    print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "    print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "\n",
    "true = expression_gt\n",
    "pred = matched_spot_expression_pred.T\n",
    "\n",
    "print(\"pred shape:\",pred.shape)\n",
    "print(\"true shape:\",true.shape)\n",
    "\n",
    "\n",
    "#genewise correlation\n",
    "corr = np.zeros(pred.shape[1])\n",
    "for i in range(pred.shape[1]):\n",
    "    corr[i] = np.corrcoef(pred[:,i], true[:,i])[0,1] #corrcoef returns a matrix\n",
    "#remove nan\n",
    "corr = corr[~np.isnan(corr)]\n",
    "print(\"Mean correlation acroalignment uniformityss cells: \", np.mean(corr))\n",
    "\n",
    "\n",
    "print(np.argsort(corr)[-5:])\n",
    "print(corr[np.argsort(corr)[-5:]])\n",
    "print(\"number of non-zero genes: \", corr.shape[0])\n",
    "print(\"mean correlation: \", np.mean(corr))\n",
    "print(\"max correlation: \", np.max(corr))\n",
    "print(\"number of genes with correlation > 0.3: \", np.sum(corr > 0.3))\n",
    "\n",
    "if save_path != \"\":\n",
    "    np.save(save_path + \"matched_spot_embeddings_pred.npy\", matched_spot_embeddings_pred.T)\n",
    "    np.save(save_path + \"matched_spot_expression_pred.npy\", matched_spot_expression_pred.T)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT:  (3460, 2000)\n",
      "top 50 HVG prediction corr : 0.39492906338777767\n",
      "top 50 HEG prediction corr : 0.32553597894014\n"
     ]
    }
   ],
   "source": [
    "top_k=50\n",
    "print(\"GT: \",true.shape)\n",
    "variances=np.var(true,axis=0)\n",
    "top_var_cols_indices=np.argsort(variances)[-top_k:][::-1]\n",
    "top_k_HVG=0\n",
    "for col_indx in top_var_cols_indices:\n",
    "    top_k_HVG+=np.corrcoef(pred[:,col_indx], true[:,col_indx])[0,1]\n",
    "print(\"top \"+str(top_k)+\" HVG prediction corr :\",top_k_HVG/top_k)\n",
    "\n",
    "cols_sum=np.sum(true,axis=0)\n",
    "top_exp_cols_indices=np.argsort(cols_sum)[-top_k:][::-1]\n",
    "top_k_HEG=0\n",
    "# print(top_exp_cols_indices.shape)\n",
    "for col_indx in top_exp_cols_indices:\n",
    "    top_k_HEG+=np.corrcoef(pred[:,col_indx], true[:,col_indx])[0,1]\n",
    "print(\"top \"+str(top_k)+\" HEG prediction corr :\",top_k_HEG/top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052043444348652525\n",
      "0.14768699171634167\n",
      "0.16805457731147716\n",
      "0.13547762368217633\n",
      "avg 0.12581565926466193\n"
     ]
    }
   ],
   "source": [
    "#select index of MG of testing slice\n",
    "#according to your dataset specifically\n",
    "\n",
    "L=[XX,XX,XX] \n",
    "average=0\n",
    "for i in range(len(L)):\n",
    "    average+=np.corrcoef(pred[:,L[i]],true[:,L[i]])[0,1]\n",
    "    print(np.corrcoef(pred[:,L[i]],true[:,L[i]])[0,1])\n",
    "print(\"avg\",average/len(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4110)\n",
      "(2000, 3460)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3460 and the array at index 1 has size 4110",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     sns\u001b[38;5;241m.\u001b[39mheatmap(corr_matrix, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, xticklabels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, yticklabels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cbar\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m plot_heatmap(expression_gt, expression_gt, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mplot_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpression_gt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatched_spot_expression_pred_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m, in \u001b[0;36mplot_heatmap\u001b[0;34m(expression_gt, matched_spot_expression_pred, top_k)\u001b[0m\n\u001b[1;32m     21\u001b[0m dendrogram \u001b[38;5;241m=\u001b[39m hierarchy\u001b[38;5;241m.\u001b[39mdendrogram(hierarchy\u001b[38;5;241m.\u001b[39mlinkage(corr_matrix, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mward\u001b[39m\u001b[38;5;124m'\u001b[39m), no_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m cluster_idx \u001b[38;5;241m=\u001b[39m dendrogram[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaves\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatched_spot_expression_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexpression_gt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m corr_matrix[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m49\u001b[39m, :]\n\u001b[1;32m     26\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m corr_matrix[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m49\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ccx_rp/lib/python3.9/site-packages/numpy/lib/function_base.py:2846\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   2844\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2845\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 2846\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2848\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ccx_rp/lib/python3.9/site-packages/numpy/lib/function_base.py:2640\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rowvar \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2639\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m-> 2640\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3460 and the array at index 1 has size 4110"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#construct heatmap of the GGC matrix\n",
    "import seaborn as sns\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "expression_gt = np.load(\"./data/filtered_expression_matrices/3/harmony3.npy\")\n",
    "matched_spot_expression_pred_1 = matched_spot_expression_pred.T\n",
    "\n",
    "print(expression_gt.shape)\n",
    "print(matched_spot_expression_pred_1.shape)\n",
    "# (3467, 2277)\n",
    "# (3467, 2277)\n",
    "#plot heatmap of top 50 genes ranked by mean\n",
    "def plot_heatmap(expression_gt, matched_spot_expression_pred, top_k=50):\n",
    "    #take mean of expression\n",
    "    mean = np.mean(expression_gt, axis=1)\n",
    "    #take ind of top 100\n",
    "    ind = np.argpartition(mean, -top_k)[-top_k:]\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr_matrix = np.corrcoef(expression_gt[ind,:])\n",
    "    dendrogram = hierarchy.dendrogram(hierarchy.linkage(corr_matrix, method='ward'), no_plot=True)\n",
    "    cluster_idx = dendrogram['leaves']\n",
    "    \n",
    "    corr_matrix = np.corrcoef(matched_spot_expression_pred[ind,:],expression_gt[ind,:])\n",
    "    corr_matrix = corr_matrix[0:49, :]\n",
    "    corr_matrix = corr_matrix[:, 0:49]\n",
    "\n",
    "    # Reorder the correlation matrix and plot the heatmap\n",
    "    plt.figure(dpi=300, figsize=(5,5))\n",
    "    sns.heatmap(corr_matrix, cmap='viridis', xticklabels=False, yticklabels=False, cbar= False, vmin=-1, vmax=1)\n",
    "\n",
    "plot_heatmap(expression_gt, expression_gt, top_k=50)\n",
    "plot_heatmap(expression_gt, matched_spot_expression_pred_1, top_k=50)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
